#Usage:
# ./1_bench.sh perf team_name
# ./1_bench.sh submit team_name

LB_URL="https://daniehua-agent-leaderboard.hf.space"


# Check team name for submit mode
if [ $1 == "perf" ] || [ $1 == "submit" ]; then
    if [ ! -z "$2" ]; then
        TEAM_NAME="$2"
    elif [ ! -z "$TEAM_NAME" ]; then
        TEAM_NAME="$TEAM_NAME"
    else
        echo "ERROR: Team name required for submit mode"
        echo "Usage: ./1_bench.sh submit <team_name>" 
        echo "Or ./1_bench.sh submit <team_name>"
        echo "Or set TEAM_NAME environment variable"
        exit 1
    fi
    echo "INFO: Using team name: $TEAM_NAME"
fi


if [ $1 == "perf" ] || [ $1 == "submit" ]; then
    echo "INFO: perf"
    date=$(date +'%b%d_%H_%M_%S')
    if [ ! -z "$PATH_TO_KERNEL_FILE" ]; then
        PATH_TO_KERNEL_FILE="$PATH_TO_KERNEL_FILE"
    else
        echo "ERROR: PATH_TO_KERNEL_FILE required for perf or submit mode, should be xxxxx.json generated by your agent "
        echo "Pls set PATH_TO_KERNEL_FILE environment variable"
        exit 1
    fi
    echo "INFO: benching kernels in $PATH_TO_KERNEL_FILE"

    geak-eval -t $TEAM_NAME -f $PATH_TO_KERNEL_FILE -o out.json -ds tbg
    result=${PATH_TO_KERNEL_FILE:0:${#PATH_TO_KERNEL_FILE}-5}
    suffix1="/out.json"
    suffix2="_perf_0.json"
    perf_file="$result$suffix1$suffix2" # reflexion_oneshot_tritonbench_9/out.json_perf_0.json
    PERF_OUTPUT=$(python show_results.py --path $perf_file)
    echo "$PERF_OUTPUT"
fi
